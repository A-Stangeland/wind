{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc67ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import cf_xarray as cfxr\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import polars as pl\n",
    "import torch\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from model import SharedPerLocationSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4fd610",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"lt\",\n",
    "    \"operating_power_max\",\n",
    "    \"mean_production\",\n",
    "    \"num_turbines\",\n",
    "    \"ELSPOT NO1\",\n",
    "    \"ELSPOT NO2\",\n",
    "    \"ELSPOT NO3\",\n",
    "    \"ELSPOT NO4\",\n",
    "    \"last_day_mean\",\n",
    "    \"last_value\",\n",
    "    \"ws10m_00\",\n",
    "    \"wd10m_00\",\n",
    "    \"t2m_00\",\n",
    "    \"rh2m_00\",\n",
    "    \"mslp_00\",\n",
    "    \"g10m_00\",\n",
    "    \"ws10m_mean\",\n",
    "    \"t2m_mean\",\n",
    "    \"rh2m_mean\",\n",
    "    \"mslp_mean\",\n",
    "    \"g10m_mean\",\n",
    "    \"ws10m_std\",\n",
    "    \"t2m_std\",\n",
    "    \"rh2m_std\",\n",
    "    \"mslp_std\",\n",
    "    \"g10m_std\",\n",
    "    \"now_air_temperature_2m\",\n",
    "    \"now_air_pressure_at_sea_level\",\n",
    "    \"now_relative_humidity_2m\",\n",
    "    \"now_precipitation_amount\",\n",
    "    \"now_wind_speed_10m\",\n",
    "    \"now_wind_direction_10m\",\n",
    "    \"sin_hod\",\n",
    "    \"cos_hod\",\n",
    "    \"sin_doy\",\n",
    "    \"cos_doy\",\n",
    "    \"sin_dow\",\n",
    "    \"cos_dow\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99e608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(ckpt_path, data_path, var_idx=2, n_points=200, plot_scaled=False):\n",
    "    device = \"cpu\"\n",
    "\n",
    "    # --- Load checkpoint & rebuild model ---\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    model_kwargs = ckpt.get(\n",
    "        \"model_kwargs\", {\"in_dim\": 7, \"hidden\": (64, 32), \"dropout\": 0.0}\n",
    "    )\n",
    "    model_kwargs[\"width\"] = model_kwargs[\"hidden\"]\n",
    "    model_kwargs.pop(\"hidden\")\n",
    "    V = model_kwargs[\"in_dim\"]\n",
    "    model = SharedPerLocationSum(**model_kwargs).to(device)\n",
    "    model.load_state_dict(ckpt[\"state_dict\"])\n",
    "    model.eval()\n",
    "\n",
    "    # Normalization stats (may be None if you trained without normalization)\n",
    "    normalize_x = bool(ckpt.get(\"normalize_x\", True))\n",
    "    normalize_y = bool(ckpt.get(\"normalize_y\", True))\n",
    "    x_mean = ckpt.get(\"x_mean\", None)\n",
    "    x_std = ckpt.get(\"x_std\", None)\n",
    "    y_mean = ckpt.get(\"y_mean\", None)\n",
    "    y_std = ckpt.get(\"y_std\", None)\n",
    "\n",
    "    if x_mean is not None:\n",
    "        x_mean = x_mean.to(device)  # shape (1, V)\n",
    "    if x_std is not None:\n",
    "        x_std = x_std.to(device)\n",
    "    if y_mean is not None:\n",
    "        y_mean = y_mean.to(device)  # scalars\n",
    "    if y_std is not None:\n",
    "        y_std = y_std.to(device)\n",
    "\n",
    "    # --- Load data to extract empirical distribution for var_idx ---\n",
    "    blob = torch.load(data_path, map_location=device)\n",
    "    X = blob[\"X\"].float()  # (N, L, V)\n",
    "\n",
    "    # Flatten over time+location for variable var_idx to get its distribution in raw units\n",
    "    x_var = X[..., var_idx].reshape(-1)  # (N*L,)\n",
    "    # Use 1%..99% quantiles to avoid extreme tails\n",
    "    qs = torch.linspace(0.01, 0.99, steps=n_points)\n",
    "    x_values = torch.quantile(x_var, qs).to(device)  # (n_points,)\n",
    "\n",
    "    # --- Build an input batch for φ evaluation ---\n",
    "    # We'll evaluate φ on single-location inputs (L=1) since φ is per-location.\n",
    "    L_eval = 1\n",
    "    base = torch.zeros(n_points, V, device=device)\n",
    "\n",
    "    # Keep other variables at the training mean if available, else dataset mean\n",
    "    if x_mean is not None:\n",
    "        base[:] = x_mean  # broadcast (1,V) -> (n_points,V)\n",
    "    else:\n",
    "        # fallback to dataset mean across (N,L) for each V\n",
    "        dataset_mean = X.mean(dim=(0, 1), keepdim=False).to(device)  # (V,)\n",
    "        base[:] = dataset_mean\n",
    "\n",
    "    # Replace var_idx with the grid of values\n",
    "    base[:, var_idx] = x_values\n",
    "\n",
    "    # Apply input normalization if used during training\n",
    "    if normalize_x and (x_mean is not None) and (x_std is not None):\n",
    "        base_norm = (base - x_mean) / (x_std + 1e-6)\n",
    "    else:\n",
    "        base_norm = base\n",
    "\n",
    "    # --- Evaluate φ directly on (n_points, V) ---\n",
    "    with torch.no_grad():\n",
    "        phi_vals = model.phi(base_norm).squeeze(-1).cpu().numpy()  # (n_points,)\n",
    "\n",
    "    # Optionally scale by y_std to bring into original target units (still missing global +y_mean)\n",
    "    if plot_scaled and normalize_y and (y_std is not None):\n",
    "        y_scale = float(y_std.cpu().numpy())\n",
    "        y_to_plot = phi_vals * y_scale\n",
    "        ylabel = \"Per-location contribution φ(x) [approx. target units (× y_std)]\"\n",
    "    else:\n",
    "        y_to_plot = phi_vals\n",
    "        ylabel = \"Per-location contribution φ(x) [normalized target units]\"\n",
    "\n",
    "    # --- Plot ---\n",
    "    xv = x_values.cpu().numpy()\n",
    "    plt.figure(figsize=(7, 4.5))\n",
    "    plt.plot(xv, y_to_plot, \"-o\")\n",
    "    # plt.xlabel(f\"Variable {var_idx} (raw units)\")\n",
    "    plt.xlabel(features[var_idx])\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(\"Learned per-location φ response\")\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4eccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"checkpoints/wind_residual_last.pth\"\n",
    "data_path = \"data/torch_dataset_all_zones.pt\"\n",
    "var_idx = 10\n",
    "n_points = 200\n",
    "plot_scaled = False\n",
    "main(ckpt_path, data_path, var_idx, n_points, plot_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090f70fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(ckpt_path)\n",
    "model_kwargs = ckpt.get(\"model_kwargs\")\n",
    "model_kwargs[\"width\"] = model_kwargs[\"hidden\"]\n",
    "model_kwargs.pop(\"hidden\")\n",
    "model = SharedPerLocationSum(**model_kwargs)\n",
    "model.load_state_dict(ckpt[\"state_dict\"])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850a78e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def scatter_phi_vs_feature_from_data(\n",
    "    ckpt_path: str,\n",
    "    data_path: str,\n",
    "    var_idx: int = 2,\n",
    "    color_idx: int = None,\n",
    "    num_pairs: int = 50000,\n",
    "    plot_scaled: bool = False,\n",
    "    overlay_median: bool = True,\n",
    "    num_bins: int = 30,\n",
    "    seed: int = 0,\n",
    "    figsize: Tuple[int, int] = (7, 4),\n",
    "    # NEW: missing-data handling\n",
    "    drop_missing: bool = True,\n",
    "    missing_idx: int = 1,\n",
    "    missing_value: float = 0.0,\n",
    "):\n",
    "    device = \"cpu\"\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # ----- load checkpoint/model\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    model_kwargs = ckpt.get(\n",
    "        \"model_kwargs\",  # {\"in_dim\": 11, \"hidden\": (64, 32), \"dropout\": 0.0}\n",
    "    )\n",
    "    model_kwargs[\"width\"] = model_kwargs[\"hidden\"]\n",
    "    model_kwargs.pop(\"hidden\")\n",
    "    V = model_kwargs[\"in_dim\"]\n",
    "    model = SharedPerLocationSum(**model_kwargs).to(device)\n",
    "    model.load_state_dict(ckpt[\"state_dict\"])\n",
    "    model.eval()\n",
    "\n",
    "    # norms\n",
    "    normalize_x = bool(ckpt.get(\"normalize_x\", True))\n",
    "    normalize_y = bool(ckpt.get(\"normalize_y\", True))\n",
    "    x_mean = ckpt.get(\"x_mean\", None)\n",
    "    x_std = ckpt.get(\"x_std\", None)\n",
    "    y_std = ckpt.get(\"y_std\", None)\n",
    "    if x_mean is not None:\n",
    "        x_mean = x_mean.to(device)\n",
    "    if x_std is not None:\n",
    "        x_std = x_std.to(device)\n",
    "    if y_std is not None:\n",
    "        y_std = y_std.to(device)\n",
    "\n",
    "    # ----- load data\n",
    "    blob = torch.load(data_path, map_location=device)\n",
    "    X = blob[\"X\"].float()  # (N, L, V)\n",
    "    N, L, Vx = X.shape\n",
    "    assert Vx == V, f\"Data V={Vx} != model V={V}\"\n",
    "\n",
    "    # ----- build valid (t, l) index set\n",
    "    if drop_missing:\n",
    "        valid_mask = X[..., missing_idx] != missing_value  # (N, L)\n",
    "    else:\n",
    "        valid_mask = torch.ones(N, L, dtype=torch.bool)\n",
    "\n",
    "    valid_pairs = valid_mask.nonzero(as_tuple=False)  # (M, 2)\n",
    "    M = valid_pairs.shape[0]\n",
    "    if M == 0:\n",
    "        raise ValueError(\n",
    "            \"No valid (timestamp, location) pairs after missing-value filter.\"\n",
    "        )\n",
    "\n",
    "    # sample K pairs uniformly from valid set\n",
    "    K = min(num_pairs, M)\n",
    "    sel = torch.randint(0, M, (K,))\n",
    "    tl = valid_pairs[sel]\n",
    "    t_idx, l_idx = tl[:, 0], tl[:, 1]\n",
    "\n",
    "    # gather raw features for plotting x-axis\n",
    "    X_pairs_raw = X[t_idx, l_idx, :]  # (K, V)\n",
    "    x_feat = X_pairs_raw[:, var_idx].clone()  # raw units\n",
    "    if color_idx is not None:\n",
    "        color_feat = X_pairs_raw[:, color_idx].clone()\n",
    "\n",
    "    # normalize inputs if used in training\n",
    "    if normalize_x and (x_mean is not None) and (x_std is not None):\n",
    "        X_pairs = (X_pairs_raw - x_mean) / (x_std + 1e-6)\n",
    "    else:\n",
    "        X_pairs = X_pairs_raw\n",
    "\n",
    "    # evaluate φ\n",
    "    phi_vals = model.phi(X_pairs).squeeze(-1)  # (K,)\n",
    "    if plot_scaled and normalize_y and (y_std is not None):\n",
    "        phi_vals = phi_vals * y_std  # approx target units (no +y_mean)\n",
    "\n",
    "    # # ----- plot\n",
    "    # plt.figure(figsize=figsize)\n",
    "    # plt.scatter(\n",
    "    #     x_feat.cpu().numpy(), phi_vals.cpu().numpy(), s=6, alpha=0.15, linewidths=0\n",
    "    # )\n",
    "    # # plt.hexbin(x_feat.cpu().numpy(), phi_vals.cpu().numpy(), gridsize=100, bins=\"log\")\n",
    "    # # plt.ylim([0, 100])\n",
    "    # # plt.xlabel(f\"Variable {var_idx} (raw units)\")\n",
    "    # plt.xlabel(features[var_idx])\n",
    "    # ylabel = \"φ(x) per location\"\n",
    "    # if plot_scaled and normalize_y and (y_std is not None):\n",
    "    #     ylabel += \" [approx. target units]\"\n",
    "    # plt.ylabel(ylabel)\n",
    "    # plt.title(\"φ vs. feature (valid samples only)\")\n",
    "\n",
    "    # # optional binned median trend\n",
    "    # if overlay_median:\n",
    "    #     x_np = x_feat.cpu().numpy()\n",
    "    #     y_np = phi_vals.cpu().numpy()\n",
    "    #     q_edges = np.linspace(0.0, 1.0, num_bins + 1)\n",
    "    #     edges = np.quantile(x_np, q_edges)\n",
    "    #     edges = np.unique(edges)\n",
    "    #     if len(edges) > 2:\n",
    "    #         bins = np.digitize(x_np, edges[1:-1], right=True)\n",
    "    #         med_x, med_y = [], []\n",
    "    #         for b in range(len(edges) - 1):\n",
    "    #             mask = bins == b\n",
    "    #             if mask.any():\n",
    "    #                 med_x.append(np.median(x_np[mask]))\n",
    "    #                 med_y.append(np.median(y_np[mask]))\n",
    "    #         if med_x:\n",
    "    #             plt.plot(med_x, med_y, \"--\", color=\"red\")\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    plot_kwargs = dict(\n",
    "        title=\"φ vs. feature (valid samples only)\",\n",
    "        height=700,\n",
    "        width=1200,\n",
    "        # opacity=0.3,\n",
    "        # trendline=\"lowess\",\n",
    "        # trendline_options=dict(frac=0.1),\n",
    "    )\n",
    "    if color_idx is not None:\n",
    "        df_plot = (\n",
    "            pl.DataFrame(\n",
    "                {\"x\": x_feat.cpu(), \"phi\": phi_vals.cpu(), \"color\": color_feat}\n",
    "            )\n",
    "            .with_columns(\n",
    "                color=pl.col(\"color\").qcut(4, labels=[f\"q{k}\" for k in range(4)])\n",
    "            )\n",
    "            .sort(\"color\")\n",
    "        )\n",
    "        # fig = px.scatter(df_plot, \"x\", \"phi\", color=\"color\", **plot_kwargs)\n",
    "        fig = px.box(df_plot, \"x\", \"phi\", color=\"color\", **plot_kwargs)\n",
    "    else:\n",
    "        df_plot = pl.DataFrame({\"x\": x_feat.cpu(), \"phi\": phi_vals.cpu()})\n",
    "        fig = px.scatter(df_plot, \"x\", \"phi\", **plot_kwargs)\n",
    "    fig.show()\n",
    "    print(\n",
    "        f\"Sampled {K} / {M} valid pairs (after filtering {missing_idx} != {missing_value}).\"\n",
    "    )\n",
    "\n",
    "\n",
    "scatter_phi_vs_feature_from_data(\n",
    "    ckpt_path=ckpt_path,\n",
    "    data_path=data_path,\n",
    "    var_idx=-6,\n",
    "    color_idx=1,\n",
    "    num_pairs=50000,\n",
    "    drop_missing=True,  # <- enable filtering\n",
    "    missing_idx=1,  # <- feature index that indicates missing\n",
    "    missing_value=0.0,  # <- treat 0 as missing\n",
    "    plot_scaled=False,\n",
    "    overlay_median=True,\n",
    "    num_bins=30,\n",
    "    figsize=(10, 7),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b8ed07",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = xr.open_dataset(\"data/dataset_all_zones.zarr\")\n",
    "ds = cfxr.decode_compress_to_multi_index(encoded, \"forecast_index\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a992fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_newest_time_ref = ds.time_ref.max()\n",
    "ds_newest = ds.sel(time_ref=ds_newest_time_ref)\n",
    "X_newest = torch.from_numpy(ds_newest[\"X\"].values)\n",
    "y_newest = torch.from_numpy(ds_newest[\"y\"].values.astype(np.float32))\n",
    "time = ds_newest.time.values\n",
    "bidding_area = ds_newest.bidding_area.values\n",
    "\n",
    "x_mean = ckpt.get(\"x_mean\", None)\n",
    "x_std = ckpt.get(\"x_std\", None)\n",
    "X_norm = (X_newest - x_mean) / x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d706dfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bidding_area = \"ELSPOT NO3\"\n",
    "lt = 1\n",
    "n_timesteps = 100\n",
    "\n",
    "ds_newest = ds.sel(bidding_area=bidding_area, lt=lt).isel(\n",
    "    forecast_index=slice(-n_timesteps, None)\n",
    ")\n",
    "X_newest = torch.from_numpy(ds_newest[\"X\"].values)\n",
    "y_newest = torch.from_numpy(ds_newest[\"y\"].values.astype(np.float32))\n",
    "time = ds_newest.time.values\n",
    "bidding_area = ds_newest.bidding_area.values\n",
    "\n",
    "x_mean = ckpt.get(\"x_mean\", None)\n",
    "x_std = ckpt.get(\"x_std\", None)\n",
    "X_norm = (X_newest - x_mean) / x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740abfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    preds = model(X_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00713906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "df_eval = pl.DataFrame(\n",
    "    {\n",
    "        \"y_true\": y_newest,\n",
    "        \"y_pred\": preds,\n",
    "        \"time\": time,\n",
    "        \"bidding_area\": bidding_area,\n",
    "    }\n",
    ")\n",
    "px.line(\n",
    "    df_eval.unpivot(index=[\"time\", \"bidding_area\"]),\n",
    "    \"time\",\n",
    "    \"value\",\n",
    "    color=\"bidding_area\",\n",
    "    line_dash=\"variable\",\n",
    ")\n",
    "\n",
    "# df_eval = pl.DataFrame(\n",
    "#     {\n",
    "#         \"y_true\": y_newest,\n",
    "#         \"y_pred\": preds,\n",
    "#         \"time\": time,\n",
    "#     }\n",
    "# )\n",
    "# px.line(\n",
    "#     df_eval.unpivot(index=[\"time\"]),\n",
    "#     \"time\",\n",
    "#     \"value\",\n",
    "#     color=\"variable\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a2f08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.pivot(\"bidding_area\", index=\"time\", values=\"y_pred\").select(\n",
    "    \"time\", \"ELSPOT NO1\", \"ELSPOT NO2\", \"ELSPOT NO3\", \"ELSPOT NO4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e86301c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.group_by(\"bidding_area\").agg(\n",
    "    RMSE=((pl.col(\"y_pred\") - pl.col(\"y_true\")) ** 2).mean().sqrt()\n",
    ").sort(\"bidding_area\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cc9711",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sqrt(((preds - y_plot) ** 2).mean()).item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wind (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
