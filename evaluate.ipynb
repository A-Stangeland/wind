{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc67ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import polars as pl\n",
    "\n",
    "# ---- Model definition matching training ----\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4fd610",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"lt\",\n",
    "    \"operating_power_max\",\n",
    "    \"last_day_mean\",\n",
    "    \"last_value\",\n",
    "    \"ws10m_00\",\n",
    "    \"wd10m_00\",\n",
    "    \"t2m_00\",\n",
    "    \"rh2m_00\",\n",
    "    \"mslp_00\",\n",
    "    \"g10m_00\",\n",
    "    \"ws10m_mean\",\n",
    "    \"t2m_mean\",\n",
    "    \"rh2m_mean\",\n",
    "    \"mslp_mean\",\n",
    "    \"g10m_mean\",\n",
    "    \"ws10m_std\",\n",
    "    \"t2m_std\",\n",
    "    \"rh2m_std\",\n",
    "    \"mslp_std\",\n",
    "    \"g10m_std\",\n",
    "    \"now_air_temperature_2m\",\n",
    "    \"now_air_pressure_at_sea_level\",\n",
    "    \"now_relative_humidity_2m\",\n",
    "    \"now_precipitation_amount\",\n",
    "    \"now_wind_speed_10m\",\n",
    "    \"now_wind_direction_10m\",\n",
    "    \"sin_hod\",\n",
    "    \"cos_hod\",\n",
    "    \"sin_doy\",\n",
    "    \"cos_doy\",\n",
    "    \"sin_dow\",\n",
    "    \"cos_dow\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99e608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedPerLocationSum(nn.Module):\n",
    "    def __init__(self, in_dim=7, hidden=(64, 32), dropout=0.0, return_locals=False):\n",
    "        super().__init__()\n",
    "        # h1, h2 = hidden\n",
    "        h1, h2, h3 = hidden\n",
    "        self.return_locals = return_locals\n",
    "        self.phi = nn.Sequential(\n",
    "            nn.Linear(in_dim, h1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(h1, h2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(h2, h3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h3, 1),  # scalar contribution per location\n",
    "            nn.Softplus(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, L, V)\n",
    "        returns:\n",
    "          y_hat: (B,) predicted total\n",
    "          (optionally) loc_contribs: (B, L)\n",
    "        \"\"\"\n",
    "        B, L, V = x.shape\n",
    "        z = x.view(B * L, V)  # flatten locations\n",
    "        contribs = self.phi(z).view(B, L)  # (B, L)\n",
    "        y_hat = contribs.sum(dim=1)  # (B,)\n",
    "        if self.return_locals:\n",
    "            return y_hat, contribs\n",
    "        return y_hat\n",
    "\n",
    "\n",
    "def main(ckpt_path, data_path, var_idx=2, n_points=200, plot_scaled=False):\n",
    "    device = \"cpu\"\n",
    "\n",
    "    # --- Load checkpoint & rebuild model ---\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    model_kwargs = ckpt.get(\n",
    "        \"model_kwargs\", {\"in_dim\": 7, \"hidden\": (64, 32), \"dropout\": 0.0}\n",
    "    )\n",
    "    V = model_kwargs[\"in_dim\"]\n",
    "    model = SharedPerLocationSum(**model_kwargs).to(device)\n",
    "    model.load_state_dict(ckpt[\"state_dict\"])\n",
    "    model.eval()\n",
    "\n",
    "    # Normalization stats (may be None if you trained without normalization)\n",
    "    normalize_x = bool(ckpt.get(\"normalize_x\", True))\n",
    "    normalize_y = bool(ckpt.get(\"normalize_y\", True))\n",
    "    x_mean = ckpt.get(\"x_mean\", None)\n",
    "    x_std = ckpt.get(\"x_std\", None)\n",
    "    y_mean = ckpt.get(\"y_mean\", None)\n",
    "    y_std = ckpt.get(\"y_std\", None)\n",
    "\n",
    "    if x_mean is not None:\n",
    "        x_mean = x_mean.to(device)  # shape (1, V)\n",
    "    if x_std is not None:\n",
    "        x_std = x_std.to(device)\n",
    "    if y_mean is not None:\n",
    "        y_mean = y_mean.to(device)  # scalars\n",
    "    if y_std is not None:\n",
    "        y_std = y_std.to(device)\n",
    "\n",
    "    # --- Load data to extract empirical distribution for var_idx ---\n",
    "    blob = torch.load(data_path, map_location=device)\n",
    "    X = blob[\"X\"].float()  # (N, L, V)\n",
    "\n",
    "    # Flatten over time+location for variable var_idx to get its distribution in raw units\n",
    "    x_var = X[..., var_idx].reshape(-1)  # (N*L,)\n",
    "    # Use 1%..99% quantiles to avoid extreme tails\n",
    "    qs = torch.linspace(0.01, 0.99, steps=n_points)\n",
    "    x_values = torch.quantile(x_var, qs).to(device)  # (n_points,)\n",
    "\n",
    "    # --- Build an input batch for φ evaluation ---\n",
    "    # We'll evaluate φ on single-location inputs (L=1) since φ is per-location.\n",
    "    L_eval = 1\n",
    "    base = torch.zeros(n_points, V, device=device)\n",
    "\n",
    "    # Keep other variables at the training mean if available, else dataset mean\n",
    "    if x_mean is not None:\n",
    "        base[:] = x_mean  # broadcast (1,V) -> (n_points,V)\n",
    "    else:\n",
    "        # fallback to dataset mean across (N,L) for each V\n",
    "        dataset_mean = X.mean(dim=(0, 1), keepdim=False).to(device)  # (V,)\n",
    "        base[:] = dataset_mean\n",
    "\n",
    "    # Replace var_idx with the grid of values\n",
    "    base[:, var_idx] = x_values\n",
    "\n",
    "    # Apply input normalization if used during training\n",
    "    if normalize_x and (x_mean is not None) and (x_std is not None):\n",
    "        base_norm = (base - x_mean) / (x_std + 1e-6)\n",
    "    else:\n",
    "        base_norm = base\n",
    "\n",
    "    # --- Evaluate φ directly on (n_points, V) ---\n",
    "    with torch.no_grad():\n",
    "        phi_vals = model.phi(base_norm).squeeze(-1).cpu().numpy()  # (n_points,)\n",
    "\n",
    "    # Optionally scale by y_std to bring into original target units (still missing global +y_mean)\n",
    "    if plot_scaled and normalize_y and (y_std is not None):\n",
    "        y_scale = float(y_std.cpu().numpy())\n",
    "        y_to_plot = phi_vals * y_scale\n",
    "        ylabel = \"Per-location contribution φ(x) [approx. target units (× y_std)]\"\n",
    "    else:\n",
    "        y_to_plot = phi_vals\n",
    "        ylabel = \"Per-location contribution φ(x) [normalized target units]\"\n",
    "\n",
    "    # --- Plot ---\n",
    "    xv = x_values.cpu().numpy()\n",
    "    plt.figure(figsize=(7, 4.5))\n",
    "    plt.plot(xv, y_to_plot, \"-o\")\n",
    "    plt.xlabel(f\"Variable {var_idx} (raw units)\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(\"Learned per-location φ response\")\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4eccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"checkpoints/wind_softplus_cawr_const_T_last.pth\"\n",
    "data_path = \"data/torch_dataset.pt\"\n",
    "var_idx = 2\n",
    "n_points = 200\n",
    "plot_scaled = False\n",
    "main(ckpt_path, data_path, var_idx, n_points, plot_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090f70fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(ckpt_path)\n",
    "model_kwargs = ckpt.get(\"model_kwargs\")\n",
    "model = SharedPerLocationSum(**model_kwargs)\n",
    "model.load_state_dict(ckpt[\"state_dict\"])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850a78e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "class SharedPerLocationSum(nn.Module):\n",
    "    def __init__(self, in_dim=7, hidden=(64, 32, 16), dropout=0.0, return_locals=False):\n",
    "        super().__init__()\n",
    "        h1, h2, h3 = hidden\n",
    "        self.return_locals = return_locals\n",
    "        self.phi = nn.Sequential(\n",
    "            nn.Linear(in_dim, h1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(h1, h2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(h2, h3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h3, 1),  # scalar per location\n",
    "            nn.Softplus(),  # keep ≥ 0 if you trained that way\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # x: (B, L, V)\n",
    "        B, L, V = x.shape\n",
    "        z = x.view(B * L, V)\n",
    "        contribs = self.phi(z).view(B, L)\n",
    "        y_hat = contribs.sum(dim=1)\n",
    "        return (y_hat, contribs) if self.return_locals else y_hat\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def scatter_phi_vs_feature_from_data(\n",
    "    ckpt_path: str,\n",
    "    data_path: str,\n",
    "    var_idx: int = 2,\n",
    "    color_idx: int = None,\n",
    "    num_pairs: int = 50000,\n",
    "    plot_scaled: bool = False,\n",
    "    overlay_median: bool = True,\n",
    "    num_bins: int = 30,\n",
    "    seed: int = 0,\n",
    "    figsize: Tuple[int, int] = (7, 4),\n",
    "    # NEW: missing-data handling\n",
    "    drop_missing: bool = True,\n",
    "    missing_idx: int = 1,\n",
    "    missing_value: float = 0.0,\n",
    "):\n",
    "    device = \"cpu\"\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # ----- load checkpoint/model\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    model_kwargs = ckpt.get(\n",
    "        \"model_kwargs\",  # {\"in_dim\": 11, \"hidden\": (64, 32), \"dropout\": 0.0}\n",
    "    )\n",
    "    V = model_kwargs[\"in_dim\"]\n",
    "    model = SharedPerLocationSum(**model_kwargs).to(device)\n",
    "    model.load_state_dict(ckpt[\"state_dict\"])\n",
    "    model.eval()\n",
    "\n",
    "    # norms\n",
    "    normalize_x = bool(ckpt.get(\"normalize_x\", True))\n",
    "    normalize_y = bool(ckpt.get(\"normalize_y\", True))\n",
    "    x_mean = ckpt.get(\"x_mean\", None)\n",
    "    x_std = ckpt.get(\"x_std\", None)\n",
    "    y_std = ckpt.get(\"y_std\", None)\n",
    "    if x_mean is not None:\n",
    "        x_mean = x_mean.to(device)\n",
    "    if x_std is not None:\n",
    "        x_std = x_std.to(device)\n",
    "    if y_std is not None:\n",
    "        y_std = y_std.to(device)\n",
    "\n",
    "    # ----- load data\n",
    "    blob = torch.load(data_path, map_location=device)\n",
    "    X = blob[\"X\"].float()  # (N, L, V)\n",
    "    N, L, Vx = X.shape\n",
    "    assert Vx == V, f\"Data V={Vx} != model V={V}\"\n",
    "\n",
    "    # ----- build valid (t, l) index set\n",
    "    if drop_missing:\n",
    "        valid_mask = X[..., missing_idx] != missing_value  # (N, L)\n",
    "    else:\n",
    "        valid_mask = torch.ones(N, L, dtype=torch.bool)\n",
    "\n",
    "    valid_pairs = valid_mask.nonzero(as_tuple=False)  # (M, 2)\n",
    "    M = valid_pairs.shape[0]\n",
    "    if M == 0:\n",
    "        raise ValueError(\n",
    "            \"No valid (timestamp, location) pairs after missing-value filter.\"\n",
    "        )\n",
    "\n",
    "    # sample K pairs uniformly from valid set\n",
    "    K = min(num_pairs, M)\n",
    "    sel = torch.randint(0, M, (K,))\n",
    "    tl = valid_pairs[sel]\n",
    "    t_idx, l_idx = tl[:, 0], tl[:, 1]\n",
    "\n",
    "    # gather raw features for plotting x-axis\n",
    "    X_pairs_raw = X[t_idx, l_idx, :]  # (K, V)\n",
    "    x_feat = X_pairs_raw[:, var_idx].clone()  # raw units\n",
    "    if color_idx is not None:\n",
    "        color_feat = X_pairs_raw[:, color_idx].clone()\n",
    "\n",
    "    # normalize inputs if used in training\n",
    "    if normalize_x and (x_mean is not None) and (x_std is not None):\n",
    "        X_pairs = (X_pairs_raw - x_mean) / (x_std + 1e-6)\n",
    "    else:\n",
    "        X_pairs = X_pairs_raw\n",
    "\n",
    "    # evaluate φ\n",
    "    phi_vals = model.phi(X_pairs).squeeze(-1)  # (K,)\n",
    "    if plot_scaled and normalize_y and (y_std is not None):\n",
    "        phi_vals = phi_vals * y_std  # approx target units (no +y_mean)\n",
    "\n",
    "    # # ----- plot\n",
    "    # plt.figure(figsize=figsize)\n",
    "    # plt.scatter(\n",
    "    #     x_feat.cpu().numpy(), phi_vals.cpu().numpy(), s=6, alpha=0.15, linewidths=0\n",
    "    # )\n",
    "    # # plt.hexbin(x_feat.cpu().numpy(), phi_vals.cpu().numpy(), gridsize=100, bins=\"log\")\n",
    "    # # plt.ylim([0, 100])\n",
    "    # # plt.xlabel(f\"Variable {var_idx} (raw units)\")\n",
    "    # plt.xlabel(features[var_idx])\n",
    "    # ylabel = \"φ(x) per location\"\n",
    "    # if plot_scaled and normalize_y and (y_std is not None):\n",
    "    #     ylabel += \" [approx. target units]\"\n",
    "    # plt.ylabel(ylabel)\n",
    "    # plt.title(\"φ vs. feature (valid samples only)\")\n",
    "\n",
    "    # # optional binned median trend\n",
    "    # if overlay_median:\n",
    "    #     x_np = x_feat.cpu().numpy()\n",
    "    #     y_np = phi_vals.cpu().numpy()\n",
    "    #     q_edges = np.linspace(0.0, 1.0, num_bins + 1)\n",
    "    #     edges = np.quantile(x_np, q_edges)\n",
    "    #     edges = np.unique(edges)\n",
    "    #     if len(edges) > 2:\n",
    "    #         bins = np.digitize(x_np, edges[1:-1], right=True)\n",
    "    #         med_x, med_y = [], []\n",
    "    #         for b in range(len(edges) - 1):\n",
    "    #             mask = bins == b\n",
    "    #             if mask.any():\n",
    "    #                 med_x.append(np.median(x_np[mask]))\n",
    "    #                 med_y.append(np.median(y_np[mask]))\n",
    "    #         if med_x:\n",
    "    #             plt.plot(med_x, med_y, \"--\", color=\"red\")\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    plot_kwargs = dict(\n",
    "        title=\"φ vs. feature (valid samples only)\",\n",
    "        height=700,\n",
    "        width=1200,\n",
    "        opacity=0.3,\n",
    "        trendline=\"lowess\",\n",
    "        trendline_options=dict(frac=0.1),\n",
    "    )\n",
    "    if color_idx is not None:\n",
    "        df_plot = (\n",
    "            pl.DataFrame(\n",
    "                {\"x\": x_feat.cpu(), \"phi\": phi_vals.cpu(), \"color\": color_feat}\n",
    "            )\n",
    "            .with_columns(\n",
    "                color=pl.col(\"color\").qcut(5, labels=[f\"q{k}\" for k in range(5)])\n",
    "            )\n",
    "            .sort(\"color\")\n",
    "        )\n",
    "        fig = px.scatter(df_plot, \"x\", \"phi\", color=\"color\", **plot_kwargs)\n",
    "    else:\n",
    "        df_plot = pl.DataFrame({\"x\": x_feat.cpu(), \"phi\": phi_vals.cpu()})\n",
    "        fig = px.scatter(df_plot, \"x\", \"phi\", **plot_kwargs)\n",
    "    fig.show()\n",
    "    print(\n",
    "        f\"Sampled {K} / {M} valid pairs (after filtering {missing_idx} != {missing_value}).\"\n",
    "    )\n",
    "\n",
    "\n",
    "scatter_phi_vs_feature_from_data(\n",
    "    ckpt_path=ckpt_path,\n",
    "    data_path=data_path,\n",
    "    var_idx=4,\n",
    "    color_idx=1,\n",
    "    num_pairs=50000,\n",
    "    drop_missing=True,  # <- enable filtering\n",
    "    missing_idx=1,  # <- feature index that indicates missing\n",
    "    missing_value=0.0,  # <- treat 0 as missing\n",
    "    plot_scaled=False,\n",
    "    overlay_median=True,\n",
    "    num_bins=30,\n",
    "    figsize=(10, 7),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e86301c",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = torch.load(data_path)\n",
    "X = blob[\"X\"].float()\n",
    "y = blob[\"y\"].float()\n",
    "\n",
    "x_mean = ckpt.get(\"x_mean\", None)\n",
    "x_std = ckpt.get(\"x_std\", None)\n",
    "X_norm = (X - x_mean) / (x_std + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce2de58",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.any(X[..., 0] == 0, dim=1)\n",
    "offset = 0\n",
    "n = 1000\n",
    "X_plot = X_norm[idx][offset : offset + n]\n",
    "y_plot = y[idx][offset : offset + n]\n",
    "with torch.no_grad():\n",
    "    preds = model(X_plot)\n",
    "\n",
    "# plt.figure(figsize=(20, 5))\n",
    "# plt.plot(y_plot, label=\"y_true\")\n",
    "# plt.plot(preds, label=\"y_pred\")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a1db64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "df_plot = pl.concat(\n",
    "    [\n",
    "        pl.DataFrame({\"var\": \"y_true\", \"val\": y_plot}).with_row_index(),\n",
    "        pl.DataFrame({\"var\": \"y_pred\", \"val\": preds}).with_row_index(),\n",
    "    ]\n",
    ")\n",
    "px.line(df_plot, \"index\", \"val\", color=\"var\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cc9711",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sqrt(((preds - y_plot) ** 2).mean()).item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wind (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
