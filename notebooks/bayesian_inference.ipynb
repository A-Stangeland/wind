{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d30f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~/projects/wind/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69f4a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import plotly.express as px\n",
    "from datetime import datetime, timedelta\n",
    "import pytensor.tensor as pt\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d68827",
   "metadata": {},
   "outputs": [],
   "source": [
    "bidding_area = \"ELSPOT NO3\"\n",
    "dataset_path = \"data/windpower_area_dataset.parquet\"\n",
    "val_cutoff = datetime(2025, 1, 1)\n",
    "data_train = (\n",
    "    pl.scan_parquet(dataset_path)\n",
    "    .filter(\n",
    "        pl.col(\"bidding_area\") == bidding_area,\n",
    "        pl.col(\"time_ref\") >= datetime(2024, 1, 1),\n",
    "        pl.col(\"time_ref\") < val_cutoff,\n",
    "        # pl.col(\"time\") >= pl.col(\"time_ref\").dt.date() + timedelta(days=1),\n",
    "        # pl.col(\"time\") < pl.col(\"time_ref\").dt.date() + timedelta(days=2),\n",
    "        (pl.col(\"time_ref\") + timedelta(days=2)).dt.date() == pl.col(\"time\").dt.date(),\n",
    "    )\n",
    "    .with_columns(lt=(pl.col(\"time\") - pl.col(\"time_ref\")).dt.total_hours())\n",
    ")\n",
    "data_val = (\n",
    "    pl.scan_parquet(dataset_path)\n",
    "    .filter(\n",
    "        pl.col(\"bidding_area\") == bidding_area,\n",
    "        pl.col(\"time_ref\") >= val_cutoff,\n",
    "        # pl.col(\"time\") >= pl.col(\"time_ref\").dt.date() + timedelta(days=1),\n",
    "        # pl.col(\"time\") < pl.col(\"time_ref\").dt.date() + timedelta(days=2),\n",
    "        (pl.col(\"time_ref\") + timedelta(days=2)).dt.date() == pl.col(\"time\").dt.date(),\n",
    "    )\n",
    "    .with_columns(lt=(pl.col(\"time\") - pl.col(\"time_ref\")).dt.total_hours())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d831e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lt = 62\n",
    "\n",
    "\n",
    "def get_emos_features(data):\n",
    "    X_mu = (\n",
    "        data.select(\n",
    "            pl.lit(1).alias(\"intercept\"),\n",
    "            \"mean_sum_pred\",\n",
    "            \"min_sum_pred\",\n",
    "            \"max_sum_pred\",\n",
    "            \"pred_lag1\",\n",
    "            \"pred_lag2\",\n",
    "            \"pred_lead1\",\n",
    "            \"pred_lead2\",\n",
    "            \"last_power\",\n",
    "            \"recent_mean\",\n",
    "            \"ramp\",\n",
    "            \"recent_max\",\n",
    "            \"recent_min\",\n",
    "            \"unavailable_transmission\",\n",
    "        )\n",
    "        .cast(pl.Float32)\n",
    "        .collect()\n",
    "        .to_numpy(order=\"c\")\n",
    "    )\n",
    "\n",
    "    X_sigma = (\n",
    "        data.select(\n",
    "            pl.lit(1).alias(\"intercept\"),\n",
    "            pl.col(\"std_sum_pred\").log().alias(\"log_std_sum_pred\"),\n",
    "            (pl.col(\"lt\") / max_lt).alias(\"lt\"),\n",
    "            \"mean_sum_pred\",\n",
    "            (pl.col(\"max_sum_pred\") - pl.col(\"min_sum_pred\"))\n",
    "            .log()\n",
    "            .alias(\"log_range_pred\"),\n",
    "            pl.col(\"recent_std\").log().alias(\"log_recent_std\"),\n",
    "            pl.col(\"ramp\").abs().log().alias(\"log_ramp\"),\n",
    "            \"unavailable_transmission\",\n",
    "        ).cast(pl.Float32)\n",
    "        .collect()\n",
    "        .to_numpy(order=\"c\")\n",
    "    )\n",
    "\n",
    "    y = data.select(\"relative_power\").collect().to_numpy()[:, 0]\n",
    "    sample_weight = data.select(\"operating_power_max\").collect().to_numpy()[:, 0]\n",
    "    return X_mu, X_sigma, y, sample_weight\n",
    "\n",
    "\n",
    "X_mu_train, X_sigma_train, y_train, sample_weight_train = get_emos_features(data_train)\n",
    "X_mu_val, X_sigma_val, y_val, sample_weight_val = get_emos_features(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125c5a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_area_capacity(path, times):\n",
    "    max_capacity = pl.scan_csv(path, try_parse_dates=True)\n",
    "\n",
    "    area_capacity = (\n",
    "        times.join(max_capacity, how=\"cross\")\n",
    "        .filter(pl.col(\"time\") >= pl.col(\"production_start_date\"))\n",
    "        .group_by(pl.col(\"time\").alias(\"time_ref\"), \"bidding_area\")\n",
    "        .agg(\n",
    "            operating_power_max=pl.col(\"operating_power_max\").sum(),\n",
    "            mean_production=pl.col(\"mean_production\").sum(),\n",
    "            num_turbines=pl.col(\"num_turbines\").sum(),\n",
    "        )\n",
    "    )\n",
    "    return area_capacity\n",
    "\n",
    "\n",
    "windpower = (\n",
    "    pl.scan_parquet(\"data/wind_power_per_bidzone.parquet\").rename(\n",
    "        {\"__index_level_0__\": \"time\"}\n",
    "    )\n",
    ").unpivot(index=\"time\", variable_name=\"bidding_area\", value_name=\"power\")\n",
    "\n",
    "times = windpower.select(pl.col(\"time\").unique())\n",
    "area_capacity = get_area_capacity(\"data/windparks_enriched.csv\", times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696f8647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# local_pred = (\n",
    "#     pl.scan_parquet(\"data/em0_model_pred.parquet\")\n",
    "#     .filter(pl.col(\"bidding_area\") == bidding_area)\n",
    "#     .group_by(\"time_ref\", \"time\", \"lt\", \"bidding_area\", \"em\")\n",
    "#     .agg(sum_local_pred=pl.col(\"local_power_pred\").sum())\n",
    "#     .join(area_capacity, on=[\"time_ref\", \"bidding_area\"])\n",
    "#     .join(windpower, on=[\"time\", \"bidding_area\"])\n",
    "#     .with_columns(\n",
    "#         sum_local_pred=pl.col(\"sum_local_pred\") / pl.col(\"operating_power_max\"),\n",
    "#     )\n",
    "#     .group_by(\"time_ref\", \"time\", \"lt\", \"bidding_area\")\n",
    "#     .agg(\n",
    "#         power=pl.col(\"power\").first(),\n",
    "#         relative_power=pl.col(\"relative_power\").first(),\n",
    "#         operating_power_max=pl.col(\"operating_power_max\").first(),\n",
    "#         mean_production=pl.col(\"mean_production\").first(),\n",
    "#         num_turbines=pl.col(\"num_turbines\").first(),\n",
    "#         mean_sum_pred=pl.col(\"sum_local_pred\").mean(),\n",
    "#         std_sum_pred=pl.col(\"sum_local_pred\").std(),\n",
    "#         min_sum_pred=pl.col(\"sum_local_pred\").min(),\n",
    "#         max_sum_pred=pl.col(\"sum_local_pred\").max(),\n",
    "#     )\n",
    "# )\n",
    "# local_pred.filter(\n",
    "#     pl.col(\"time_ref\").dt.date() == datetime(2025, 1, 1), pl.col(\"lt\") == 39\n",
    "# ).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e009ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from wind.model.pred_area_bayesian import BayesianAreaModel, get_emos_features\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class EvalResult:\n",
    "    name: str\n",
    "    rmse: float\n",
    "    crps: float\n",
    "\n",
    "\n",
    "def per_observation_crps(y_true: np.ndarray, y_pred: np.ndarray) -> np.ndarray:\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    if y_pred.shape[1:] != (1,) * (y_pred.ndim - y_true.ndim - 1) + y_true.shape:\n",
    "        raise ValueError(\n",
    "            f\"\"\"Expected y_pred to have one extra sample dim on left.\n",
    "                Actual shapes: {y_pred.shape} versus {y_true.shape}\"\"\"\n",
    "        )\n",
    "\n",
    "    absolute_error = np.mean(np.abs(y_pred - y_true), axis=0)\n",
    "\n",
    "    num_samples = y_pred.shape[0]\n",
    "    if num_samples == 1:\n",
    "        return absolute_error\n",
    "\n",
    "    y_pred = np.sort(y_pred, axis=0)\n",
    "    diff = y_pred[1:] - y_pred[:-1]\n",
    "    weight = np.arange(1, num_samples) * np.arange(num_samples - 1, 0, -1)\n",
    "    weight = weight.reshape(weight.shape + (1,) * (diff.ndim - 1))\n",
    "\n",
    "    return absolute_error - np.sum(diff * weight, axis=0) / num_samples**2\n",
    "\n",
    "\n",
    "def crps(\n",
    "    y_true: np.ndarray,\n",
    "    y_pred: np.ndarray,\n",
    "    sample_weight: np.ndarray | None = None,\n",
    ") -> float:\n",
    "    return float(\n",
    "        np.average(per_observation_crps(y_true, y_pred), weights=sample_weight)\n",
    "    )\n",
    "\n",
    "\n",
    "def evaluate_bayesian(y_true: pl.LazyFrame) -> EvalResult:\n",
    "    val_cutoff = y_true.select(pl.col(\"time_ref\").min()).collect().item()\n",
    "    data = pl.scan_parquet(\"data/windpower_area_dataset.parquet\").filter(\n",
    "        pl.col(\"time\").dt.date() == (pl.col(\"time_ref\") + timedelta(days=2)).dt.date()\n",
    "    )\n",
    "\n",
    "    df_train = (\n",
    "        data.filter(\n",
    "            pl.col(\"time_ref\") < val_cutoff,\n",
    "            pl.col(\"time_ref\") >= val_cutoff - timedelta(days=365),\n",
    "            pl.col(\"relative_power\").is_not_null(),\n",
    "        )\n",
    "        .sort(\"bidding_area\", \"time_ref\", \"time\")\n",
    "        .select(\n",
    "            pl.col(\"*\").fill_null(strategy=\"forward\").over(\"bidding_area\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df_val = (\n",
    "        y_true.join(data, on=[\"bidding_area\", \"time_ref\", \"time\"], how=\"left\")\n",
    "        .sort(\"bidding_area\", \"time_ref\", \"time\")\n",
    "        .select(\n",
    "            pl.col(\"*\").fill_null(strategy=\"forward\").over(\"bidding_area\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    preds = []\n",
    "    for bidding_area in [\"ELSPOT NO1\", \"ELSPOT NO2\", \"ELSPOT NO3\", \"ELSPOT NO4\"]:\n",
    "        X_mu_train, X_sigma_train, y_train, scaling_factor_train = get_emos_features(\n",
    "            df_train.filter(pl.col(\"bidding_area\") == bidding_area)\n",
    "        )\n",
    "        X_mu_val, X_sigma_val, y_val, scaling_factor_val = get_emos_features(\n",
    "            df_val.filter(pl.col(\"bidding_area\") == bidding_area)\n",
    "        )\n",
    "        print(\n",
    "            np.isnan(X_mu_train).sum(),\n",
    "            np.isnan(X_sigma_train).sum(),\n",
    "            np.isnan(X_mu_val).sum(),\n",
    "            np.isnan(X_sigma_val).sum(),\n",
    "        )\n",
    "        area_model = BayesianAreaModel()\n",
    "        area_model.fit(X_mu_train, X_sigma_train, y_train, tune=100, draws=100)\n",
    "        samples = area_model.predict(X_mu_val, X_sigma_val) * np.expand_dims(\n",
    "            scaling_factor_val, 1\n",
    "        )\n",
    "        preds.append(samples)\n",
    "\n",
    "    pred_samples = np.concat(preds, axis=0)\n",
    "    print(pred_samples.shape)\n",
    "    pred_mean = np.mean(pred_samples, axis=1)\n",
    "    y_true_values = df_val.select(\"y_true\").collect().to_numpy()[:, 0]\n",
    "    rmse_score = np.sqrt(np.mean((y_true_values - pred_mean) ** 2))\n",
    "    crps_score = crps(y_true_values, pred_samples)\n",
    "    return EvalResult(\"Bayesian Calibrator\", rmse_score, crps_score)\n",
    "\n",
    "\n",
    "def get_eval_set(\n",
    "    eval_start: datetime = datetime(2025, 1, 1), eval_stop: datetime | None = None\n",
    "):\n",
    "    area_power = (\n",
    "        pl.scan_parquet(\"data/wind_power_per_bidzone.parquet\").rename(\n",
    "            {\"__index_level_0__\": \"time\"}\n",
    "        )\n",
    "    ).unpivot(index=\"time\", variable_name=\"bidding_area\", value_name=\"y_true\")\n",
    "\n",
    "    y_true = (\n",
    "        area_power.select(\"bidding_area\", pl.col(\"time\").alias(\"time_ref\"))\n",
    "        .filter(\n",
    "            pl.col(\"time_ref\") >= eval_start,\n",
    "            pl.col(\"time_ref\").dt.hour() == 9,\n",
    "        )\n",
    "        .join(area_power, on=\"bidding_area\")\n",
    "        .filter(\n",
    "            pl.col(\"time\").dt.date()\n",
    "            == (pl.col(\"time_ref\") + timedelta(days=2)).dt.date()\n",
    "        )\n",
    "        .select(\n",
    "            \"bidding_area\",\n",
    "            \"time_ref\",\n",
    "            \"time\",\n",
    "            (pl.col(\"time\") - pl.col(\"time_ref\")).dt.total_hours().alias(\"lt\"),\n",
    "            \"y_true\",\n",
    "        )\n",
    "    )\n",
    "    return y_true\n",
    "\n",
    "\n",
    "y_true = get_eval_set()\n",
    "\n",
    "val_cutoff = y_true.select(pl.col(\"time_ref\").min()).collect().item()\n",
    "data = pl.scan_parquet(\"data/windpower_area_dataset.parquet\").filter(\n",
    "    pl.col(\"time\").dt.date() == (pl.col(\"time_ref\") + timedelta(days=2)).dt.date()\n",
    ")\n",
    "\n",
    "df_train = (\n",
    "    data.filter(\n",
    "        pl.col(\"time_ref\") < val_cutoff,\n",
    "        pl.col(\"time_ref\") >= val_cutoff - timedelta(days=365),\n",
    "        pl.col(\"relative_power\").is_not_null(),\n",
    "    )\n",
    "    .sort(\"bidding_area\", \"time_ref\", \"time\")\n",
    "    .select(\n",
    "        pl.col(\"*\").fill_null(strategy=\"forward\").over(\"bidding_area\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "df_val = (\n",
    "    y_true.join(data, on=[\"bidding_area\", \"time_ref\", \"time\"], how=\"left\")\n",
    "    .sort(\"bidding_area\", \"time_ref\", \"time\")\n",
    "    .select(\n",
    "        pl.col(\"*\").fill_null(strategy=\"forward\").over(\"bidding_area\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "preds = []\n",
    "# def run_model(bidding_area)\n",
    "\n",
    "# for bidding_area in [\"ELSPOT NO1\", \"ELSPOT NO2\", \"ELSPOT NO3\", \"ELSPOT NO4\"]:\n",
    "for bidding_area in [\"ELSPOT NO2\"]:\n",
    "    X_mu_train, X_sigma_train, y_train, scaling_factor_train = get_emos_features(\n",
    "        df_train.filter(pl.col(\"bidding_area\") == bidding_area)\n",
    "    )\n",
    "    X_mu_val, X_sigma_val, y_val, scaling_factor_val = get_emos_features(\n",
    "        df_val.filter(pl.col(\"bidding_area\") == bidding_area)\n",
    "    )\n",
    "    # print(\n",
    "    #     np.isnan(X_mu_train).sum(),\n",
    "    #     np.isnan(X_sigma_train).sum(),\n",
    "    #     np.isnan(X_mu_val).sum(),\n",
    "    #     np.isnan(X_sigma_val).sum(),\n",
    "    # )\n",
    "    # area_model = BayesianAreaModel()\n",
    "    # area_model.fit(X_mu_train, X_sigma_train, y_train, tune=100, draws=100)\n",
    "    # samples = area_model.predict(X_mu_val, X_sigma_val) * np.expand_dims(\n",
    "    #     scaling_factor_val, 1\n",
    "    # )\n",
    "    # preds.append(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fd72d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_emos_pymc(\n",
    "    X_mu,\n",
    "    X_sigma,\n",
    "    y,\n",
    "    draws=1500,\n",
    "    tune=1500,\n",
    "    target_accept=0.9,\n",
    "    chains=4,\n",
    "    seed=123,\n",
    "):\n",
    "    with pm.Model() as model:\n",
    "        Xmu = pm.Data(\"Xmu\", X_mu)\n",
    "        Xsig = pm.Data(\"Xsig\", X_sigma)\n",
    "        y_obs = pm.Data(\"y_obs\", y)\n",
    "\n",
    "        # Priors\n",
    "        beta = pm.Normal(\"beta\", mu=0.0, sigma=2.0, shape=X_mu.shape[1])\n",
    "        gamma = pm.Normal(\"gamma\", mu=0.0, sigma=0.2, shape=X_sigma.shape[1])\n",
    "\n",
    "        # Linear predictors\n",
    "        mu = pm.Deterministic(\"mu\", pt.dot(Xmu, beta))  # logit-mean\n",
    "        log_sig = pm.Deterministic(\"log_sigma\", pt.dot(Xsig, gamma))\n",
    "        sigma = pm.Deterministic(\"sigma\", pt.exp(log_sig))  # > 0\n",
    "\n",
    "        # Likelihood on capacity factor (0,1) via LogitNormal\n",
    "        pm.LogitNormal(\n",
    "            \"y\", mu=mu, sigma=sigma, observed=y_obs\n",
    "        )  # bounds handled by dist\n",
    "\n",
    "        idata = pm.sample(\n",
    "            draws=draws,\n",
    "            tune=tune,\n",
    "            chains=chains,\n",
    "            cores=chains,\n",
    "            # target_accept=target_accept,\n",
    "            random_seed=seed,\n",
    "            progressbar=True,\n",
    "            nuts_sampler=\"nutpie\",\n",
    "            # nuts_sampler_kwargs=dict(backend=\"jax\"),\n",
    "        )\n",
    "    return model, idata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf513a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, idata = fit_emos_pymc(\n",
    "    X_mu_train,\n",
    "    X_sigma_train,\n",
    "    y_train,\n",
    "    draws=1000,\n",
    "    tune=1000,\n",
    "    chains=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba576036",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.model_to_graphviz(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d68e77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = az.plot_trace(idata, var_names=\"beta\", compact=False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e463d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    prior_pred = pm.sample_prior_predictive(draws=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a85c6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(\n",
    "    pl.DataFrame(\n",
    "        prior_pred.prior_predictive[\"y\"].stack(sample=(\"chain\", \"draw\")).values,\n",
    "        schema=[str(k) for k in range(10)],\n",
    "    ).unpivot(),\n",
    "    \"value\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec3e9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(\n",
    "    pl.concat(\n",
    "        [\n",
    "            pl.DataFrame(\n",
    "                prior_pred.prior_predictive[\"y\"].stack(sample=(\"chain\", \"draw\")).values,\n",
    "                schema=[str(k) for k in range(10)],\n",
    "            ),\n",
    "            data_train.select(\"time\", \"time_ref\", \"lt\").collect(),\n",
    "        ],\n",
    "        how=\"horizontal\",\n",
    "    ).unpivot(index=[\"time\", \"time_ref\", \"lt\"]),\n",
    "    # .filter(pl.col(\"time\") < pl.col(\"time_ref\").dt.date() + timedelta(days=2)),\n",
    "    \"time_ref\",\n",
    "    \"value\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe755db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emos_quantiles(\n",
    "    model, idata, X_mu_new, X_sigma_new, q=(0.025, 0.05, 0.5, 0.95, 0.975)\n",
    "):\n",
    "    with model:\n",
    "        pm.set_data(\n",
    "            {\n",
    "                \"Xmu\": X_mu_new,\n",
    "                \"Xsig\": X_sigma_new,\n",
    "                \"y_obs\": np.zeros(X_mu_new.shape[0], dtype=np.float32),\n",
    "            }\n",
    "        )\n",
    "        ppc = pm.sample_posterior_predictive(idata)\n",
    "\n",
    "    # ppc[\"y\"] has shape (n_draws*chains, n_obs)\n",
    "    posterior = ppc.posterior_predictive[\"y\"].stack(sample=(\"chain\", \"draw\"))\n",
    "    samples = posterior.transpose(\"sample\", \"y_dim_0\").values\n",
    "    # Quantiles per observation\n",
    "    qs = np.quantile(samples, q, axis=0).T\n",
    "    out = pl.DataFrame(qs, schema=[f\"q{int(1000 * qq):03d}\" for qq in q]).with_columns(\n",
    "        pred_mean=samples.mean(axis=0),\n",
    "        pred_std=samples.std(axis=0, ddof=1),\n",
    "    )\n",
    "    return (\n",
    "        out,\n",
    "        posterior,\n",
    "    )  # samples  # you can keep samples for scenario generation / ECC later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd85189a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, posterior = predict_emos_quantiles(model, idata, X_mu_val, X_sigma_val)\n",
    "# out, posterior = predict_emos_quantiles(model, idata, X_mu_train, X_sigma_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91a370c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot[\"operating_power_max\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e907383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = pl.concat([data_val.collect(), out], how=\"horizontal\").filter(\n",
    "    pl.col(\"time\") >= datetime(2025, 1, 1),\n",
    "    pl.col(\"time\") < datetime(2025, 1, 20),\n",
    "    )\n",
    "# df_plot = pl.concat([data_train.collect(), out], how=\"horizontal\")\n",
    "\n",
    "fig = go.Figure(\n",
    "    [\n",
    "        go.Scatter(\n",
    "            name=\"y_true\",\n",
    "            x=df_plot[\"time\"],\n",
    "            y=df_plot[\"relative_power\"] * df_plot[\"operating_power_max\"],\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"rgb(237, 55, 31)\"),\n",
    "        ),\n",
    "        go.Scatter(\n",
    "            name=\"y_pred\",\n",
    "            x=df_plot[\"time\"],\n",
    "            y=df_plot[\"pred_mean\"] * df_plot[\"operating_power_max\"],\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"rgb(31, 119, 180)\"),\n",
    "        ),\n",
    "        go.Scatter(\n",
    "            name=\"Upper Bound alpha-50\",\n",
    "            x=df_plot[\"time\"],\n",
    "            y=df_plot[\"q950\"] * df_plot[\"operating_power_max\"],\n",
    "            mode=\"lines\",\n",
    "            marker=dict(color=\"#444\"),\n",
    "            line=dict(width=0),\n",
    "            showlegend=False,\n",
    "        ),\n",
    "        go.Scatter(\n",
    "            name=\"Lower Bound alpha-50\",\n",
    "            x=df_plot[\"time\"],\n",
    "            y=df_plot[\"q050\"] * df_plot[\"operating_power_max\"],\n",
    "            marker=dict(color=\"#444\"),\n",
    "            line=dict(width=0),\n",
    "            mode=\"lines\",\n",
    "            fillcolor=\"rgba(68, 68, 68, 0.3)\",\n",
    "            fill=\"tonexty\",\n",
    "            showlegend=False,\n",
    "        ),\n",
    "        # go.Scatter(\n",
    "        #     name=\"Upper Bound alpha-5\",\n",
    "        #     x=df_plot[\"time\"],\n",
    "        #     y=df_plot[\"q975\"],\n",
    "        #     mode=\"lines\",\n",
    "        #     marker=dict(color=\"#444\"),\n",
    "        #     line=dict(width=0),\n",
    "        #     showlegend=False,\n",
    "        # ),\n",
    "        # go.Scatter(\n",
    "        #     name=\"Lower Bound alpha-5\",\n",
    "        #     x=df_plot[\"time\"],\n",
    "        #     y=df_plot[\"q025\"],\n",
    "        #     marker=dict(color=\"#444\"),\n",
    "        #     line=dict(width=0),\n",
    "        #     mode=\"lines\",\n",
    "        #     fillcolor=\"rgba(68, 68, 68, 0.15)\",\n",
    "\n",
    "        #     fill=\"tonexty\",\n",
    "        #     showlegend=False,\n",
    "        # ),\n",
    "    ]\n",
    ")\n",
    "# [fig.add_vline(x=x) for x in df_plot[\"time_ref\"].unique()]\n",
    "fig.update_layout(\n",
    "    yaxis=dict(title=dict(text=\"Power\")),\n",
    "    # title=dict(text=\"Continuous, variable value error bars\"),\n",
    "    hovermode=\"x\",\n",
    ")\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.update_layout(\n",
    "    autosize=False,  # Set to False to manually control width and height\n",
    "    width=800,       # Set the desired width in pixels\n",
    "    height=400       # Set the desired height in pixels\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddecb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot.with_columns(\n",
    "    # under=pl.col(\"relative_power\") < pl.col(\"q250\"),\n",
    "    # over=pl.col(\"relative_power\") > pl.col(\"q750\"),\n",
    "    under=pl.col(\"relative_power\") < pl.col(\"q025\"),\n",
    "    over=pl.col(\"relative_power\") > pl.col(\"q975\"),\n",
    ").select(\n",
    "    pl.col(\"under\").mean(),\n",
    "    (~pl.col(\"under\") & ~pl.col(\"over\")).mean().alias(\"in\"),\n",
    "    pl.col(\"over\").mean(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf006e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_observation_crps(y_true: np.ndarray, y_pred: np.ndarray) -> np.ndarray:\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    if y_pred.shape[1:] != (1,) * (y_pred.ndim - y_true.ndim - 1) + y_true.shape:\n",
    "        raise ValueError(\n",
    "            f\"\"\"Expected y_pred to have one extra sample dim on left.\n",
    "                Actual shapes: {y_pred.shape} versus {y_true.shape}\"\"\"\n",
    "        )\n",
    "\n",
    "    absolute_error = np.mean(np.abs(y_pred - y_true), axis=0)\n",
    "\n",
    "    num_samples = y_pred.shape[0]\n",
    "    if num_samples == 1:\n",
    "        return absolute_error\n",
    "\n",
    "    y_pred = np.sort(y_pred, axis=0)\n",
    "    diff = y_pred[1:] - y_pred[:-1]\n",
    "    weight = np.arange(1, num_samples) * np.arange(num_samples - 1, 0, -1)\n",
    "    weight = weight.reshape(weight.shape + (1,) * (diff.ndim - 1))\n",
    "\n",
    "    return absolute_error - np.sum(diff * weight, axis=0) / num_samples**2\n",
    "\n",
    "\n",
    "def crps(\n",
    "    y_true: np.ndarray,\n",
    "    y_pred: np.ndarray,\n",
    "    sample_weight: np.ndarray | None = None,\n",
    "):\n",
    "    return np.average(per_observation_crps(y_true, y_pred), weights=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707baf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "capacity = data_val.select(\"operating_power_max\").collect().to_series().to_numpy()\n",
    "y_true = y_val * capacity\n",
    "y_pred = posterior.transpose(\"sample\", \"y_dim_0\").values * capacity\n",
    "\n",
    "print(f\"CRPS: {crps(y_true, y_pred)}\")\n",
    "print(f\"RMSE: {root_mean_squared_error(y_true, np.mean(y_pred, axis=0))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cb29f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
